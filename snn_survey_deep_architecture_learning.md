# [Deep Learning in Spiking Neural Networks](https://arxiv.org/pdf/1804.08150.pdf)

**Authors**: Amirhossein Tavanaei, Masoud Ghodrati, Saeed Reza Kheradpisheh, Timothee Masquelier, and Anthony Maida, 2019

### Motivation 

* A review of supervised an unsupervised training algorithms for spiking neural networks is presented. The methods compared are evaluated in terms of the accuracy they produce, computational cost required, and compatibility with existing hardware platforms.
* A conclusion is that while spiking networks are still being outperformed by classical networks, this gap is decreasing.
* The review looks at feedforward networks, convolutional networks, restricted Boltzmann machines, spiking deep belief networks and recurrent networks.
* For each method included a description of the method architetcure and learning approach is given.


### Design observations/decisions

### Contributions


<!-- recent reviews of dnn see references 3 and 4 -->
<!-- examples of training methods that restrict architectures to single layers:: In many existing spiking networks, learning is restricted
to a single layer, for example [59], [60], [61]. -->

<!--  Also,
theoretical and experimental results show better performance of deep rather than wide structures [123], [124],
[125]. -->